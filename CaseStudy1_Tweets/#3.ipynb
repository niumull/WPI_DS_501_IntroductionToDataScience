{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1. Authorizing an application to access Twitter account data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x0000020F1BA9BDD8>\n"
     ]
    }
   ],
   "source": [
    "# I had to add this because the ipython notebook could not find the Twitter library on my computer.\n",
    "# You may not need to add these first two lines\n",
    "import sys\n",
    "sys.path.append('/home/matt/Enthought/Canopy_64bit/User/lib/python2.7/site-packages')\n",
    "import twitter\n",
    "# Go to http://dev.twitter.com/apps/new to create an app and get values\n",
    "# for these credentials, which you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "# on Twitter's OAuth implementation.\n",
    "\n",
    "# CONSUMER_KEY = 'Tx8GozuzaraJO89LypsTqFUNM'\n",
    "# CONSUMER_SECRET ='uC0KPaRZjGY0qoNJAxBQb0jbb3Us4DXJVKFCP1qtSfjFgbRvd0'\n",
    "# OAUTH_TOKEN = '571213367-BC7MYnWpLbvy2AYhvqCu6Fh1EIeFasPxo0Y8uBEn'\n",
    "# OAUTH_TOKEN_SECRET = 'KA9GddiLbVwummLoSGmDYMNQFVaR3P4YiGo7Zs6D5e7Qz'\n",
    "\n",
    "CONSUMER_KEY = 'YBicfvPPR7YmsJdFtd8qGATmI'\n",
    "CONSUMER_SECRET ='YYXKSBw5n6b5dpbwmMfZTjqJcUnDQm6fxlNUEnf63k5idJsj2m'\n",
    "OAUTH_TOKEN = '774076984561430528-1ENguVW2E40PSue6YWnDuCBUyASjhGB'\n",
    "OAUTH_TOKEN_SECRET = 'ZcjrXboPxPmGEXzq2n1GQN1s7u8ZAXQeKWDSVIrZxQMkV'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import twitter\n",
    "\n",
    "def twitter_trends(twitter_api, woe_id):\n",
    "    # Prefix ID with the underscore for query string parameterization.\n",
    "    # Without the underscore, the twitter package appends the ID value\n",
    "    # to the URL itself as a special-case keyword argument.\n",
    "    return twitter_api.trends.place(_id=woe_id)\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/ for details on\n",
    "# Yahoo! Where On Earth ID\n",
    "\n",
    "WORLD_WOE_ID = 1\n",
    "world_trends = twitter_trends(twitter_api, WORLD_WOE_ID)\n",
    "#print (json.dumps(world_trends, indent=1))\n",
    "\n",
    "US_WOE_ID = 23424977\n",
    "us_trends = twitter_trends(twitter_api, US_WOE_ID)\n",
    "#print (json.dumps(us_trends, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"possibly_sensitive\": false,\n",
      " \"in_reply_to_user_id_str\": null,\n",
      " \"truncated\": false,\n",
      " \"created_at\": \"Tue Sep 20 01:35:38 +0000 2016\",\n",
      " \"in_reply_to_status_id_str\": null,\n",
      " \"favorite_count\": 0,\n",
      " \"entities\": {\n",
      "  \"hashtags\": [],\n",
      "  \"user_mentions\": [\n",
      "   {\n",
      "    \"id\": 3068796514,\n",
      "    \"name\": \"BuffBoxx\",\n",
      "    \"indices\": [\n",
      "     3,\n",
      "     12\n",
      "    ],\n",
      "    \"screen_name\": \"buffboxx\",\n",
      "    \"id_str\": \"3068796514\"\n",
      "   }\n",
      "  ],\n",
      "  \"urls\": [\n",
      "   {\n",
      "    \"url\": \"https://t.co/Wl1aDP0pxN\",\n",
      "    \"expanded_url\": \"http://ow.ly/41W8504xFDy\",\n",
      "    \"indices\": [\n",
      "     67,\n",
      "     90\n",
      "    ],\n",
      "    \"display_url\": \"ow.ly/41W8504xFDy\"\n",
      "   }\n",
      "  ],\n",
      "  \"symbols\": []\n",
      " },\n",
      " \"in_reply_to_status_id\": null,\n",
      " \"id\": 778044917532721152,\n",
      " \"coordinates\": null,\n",
      " \"place\": null,\n",
      " \"user\": {\n",
      "  \"default_profile\": false,\n",
      "  \"is_translator\": false,\n",
      "  \"profile_background_color\": \"131516\",\n",
      "  \"created_at\": \"Sun Aug 22 00:40:37 +0000 2010\",\n",
      "  \"description\": \"Fotografia & Video https://t.co/g4m8Vhy8Wp\",\n",
      "  \"profile_sidebar_border_color\": \"000000\",\n",
      "  \"follow_request_sent\": false,\n",
      "  \"listed_count\": 63,\n",
      "  \"protected\": false,\n",
      "  \"entities\": {\n",
      "   \"url\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"https://t.co/LKeGob5fcm\",\n",
      "      \"expanded_url\": \"https://www.instagram.com/aaronalva\",\n",
      "      \"indices\": [\n",
      "       0,\n",
      "       23\n",
      "      ],\n",
      "      \"display_url\": \"instagram.com/aaronalva\"\n",
      "     }\n",
      "    ]\n",
      "   },\n",
      "   \"description\": {\n",
      "    \"urls\": [\n",
      "     {\n",
      "      \"url\": \"https://t.co/g4m8Vhy8Wp\",\n",
      "      \"expanded_url\": \"http://facebook.com/fotografoaaronalva\",\n",
      "      \"indices\": [\n",
      "       19,\n",
      "       42\n",
      "      ],\n",
      "      \"display_url\": \"facebook.com/fotografoaaron\\u2026\"\n",
      "     }\n",
      "    ]\n",
      "   }\n",
      "  },\n",
      "  \"profile_use_background_image\": true,\n",
      "  \"default_profile_image\": false,\n",
      "  \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/181360785/1445310016\",\n",
      "  \"url\": \"https://t.co/LKeGob5fcm\",\n",
      "  \"statuses_count\": 7680,\n",
      "  \"profile_image_url\": \"http://pbs.twimg.com/profile_images/656303770037583872/QZ24Edfn_normal.jpg\",\n",
      "  \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/731879398/c567d3435ebedfc528d5f720f7fc6cae.jpeg\",\n",
      "  \"profile_link_color\": \"FA743E\",\n",
      "  \"screen_name\": \"aaronalva\",\n",
      "  \"contributors_enabled\": false,\n",
      "  \"notifications\": false,\n",
      "  \"location\": \"Peru\",\n",
      "  \"name\": \"Aar\\u00f3n Alva\",\n",
      "  \"following\": false,\n",
      "  \"profile_text_color\": \"009999\",\n",
      "  \"followers_count\": 501,\n",
      "  \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/656303770037583872/QZ24Edfn_normal.jpg\",\n",
      "  \"is_translation_enabled\": false,\n",
      "  \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/731879398/c567d3435ebedfc528d5f720f7fc6cae.jpeg\",\n",
      "  \"time_zone\": \"Quito\",\n",
      "  \"profile_background_tile\": true,\n",
      "  \"utc_offset\": -18000,\n",
      "  \"friends_count\": 1303,\n",
      "  \"geo_enabled\": true,\n",
      "  \"verified\": false,\n",
      "  \"id_str\": \"181360785\",\n",
      "  \"id\": 181360785,\n",
      "  \"favourites_count\": 265,\n",
      "  \"profile_sidebar_fill_color\": \"EFEFEF\",\n",
      "  \"lang\": \"es\",\n",
      "  \"has_extended_profile\": true\n",
      " },\n",
      " \"favorited\": false,\n",
      " \"retweeted_status\": {\n",
      "  \"possibly_sensitive\": false,\n",
      "  \"in_reply_to_user_id_str\": null,\n",
      "  \"truncated\": false,\n",
      "  \"created_at\": \"Tue Sep 20 00:04:27 +0000 2016\",\n",
      "  \"in_reply_to_status_id_str\": null,\n",
      "  \"favorite_count\": 0,\n",
      "  \"entities\": {\n",
      "   \"hashtags\": [],\n",
      "   \"user_mentions\": [],\n",
      "   \"urls\": [\n",
      "    {\n",
      "     \"url\": \"https://t.co/Wl1aDP0pxN\",\n",
      "     \"expanded_url\": \"http://ow.ly/41W8504xFDy\",\n",
      "     \"indices\": [\n",
      "      53,\n",
      "      76\n",
      "     ],\n",
      "     \"display_url\": \"ow.ly/41W8504xFDy\"\n",
      "    }\n",
      "   ],\n",
      "   \"symbols\": []\n",
      "  },\n",
      "  \"in_reply_to_status_id\": null,\n",
      "  \"id\": 778021969203720192,\n",
      "  \"coordinates\": null,\n",
      "  \"place\": null,\n",
      "  \"user\": {\n",
      "   \"default_profile\": true,\n",
      "   \"is_translator\": false,\n",
      "   \"profile_background_color\": \"C0DEED\",\n",
      "   \"created_at\": \"Tue Mar 03 22:52:34 +0000 2015\",\n",
      "   \"description\": \"A subscription box company curating monthly boxes w/ @Reebok athletic apparel & brand name fitness products. A part of each sale goes to our charity partners\",\n",
      "   \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "   \"follow_request_sent\": false,\n",
      "   \"listed_count\": 53,\n",
      "   \"protected\": false,\n",
      "   \"entities\": {\n",
      "    \"url\": {\n",
      "     \"urls\": [\n",
      "      {\n",
      "       \"url\": \"https://t.co/MCXvOirja1\",\n",
      "       \"expanded_url\": \"http://buffboxx.co\",\n",
      "       \"indices\": [\n",
      "        0,\n",
      "        23\n",
      "       ],\n",
      "       \"display_url\": \"buffboxx.co\"\n",
      "      }\n",
      "     ]\n",
      "    },\n",
      "    \"description\": {\n",
      "     \"urls\": []\n",
      "    }\n",
      "   },\n",
      "   \"profile_use_background_image\": true,\n",
      "   \"default_profile_image\": false,\n",
      "   \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/3068796514/1454032839\",\n",
      "   \"url\": \"https://t.co/MCXvOirja1\",\n",
      "   \"statuses_count\": 4518,\n",
      "   \"profile_image_url\": \"http://pbs.twimg.com/profile_images/583383123724914688/uu42tul9_normal.jpg\",\n",
      "   \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "   \"profile_link_color\": \"0084B4\",\n",
      "   \"screen_name\": \"buffboxx\",\n",
      "   \"contributors_enabled\": false,\n",
      "   \"notifications\": false,\n",
      "   \"location\": \"USA\",\n",
      "   \"name\": \"BuffBoxx\",\n",
      "   \"following\": false,\n",
      "   \"profile_text_color\": \"333333\",\n",
      "   \"followers_count\": 7600,\n",
      "   \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/583383123724914688/uu42tul9_normal.jpg\",\n",
      "   \"is_translation_enabled\": false,\n",
      "   \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "   \"time_zone\": \"Pacific Time (US & Canada)\",\n",
      "   \"profile_background_tile\": false,\n",
      "   \"utc_offset\": -25200,\n",
      "   \"friends_count\": 4530,\n",
      "   \"geo_enabled\": false,\n",
      "   \"verified\": false,\n",
      "   \"id_str\": \"3068796514\",\n",
      "   \"id\": 3068796514,\n",
      "   \"favourites_count\": 24206,\n",
      "   \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "   \"lang\": \"en\",\n",
      "   \"has_extended_profile\": false\n",
      "  },\n",
      "  \"favorited\": false,\n",
      "  \"text\": \"Take a Day Off Between CrossFit Workouts, Study Says https://t.co/Wl1aDP0pxN\",\n",
      "  \"lang\": \"en\",\n",
      "  \"geo\": null,\n",
      "  \"is_quote_status\": false,\n",
      "  \"retweet_count\": 1,\n",
      "  \"metadata\": {\n",
      "   \"iso_language_code\": \"en\",\n",
      "   \"result_type\": \"recent\"\n",
      "  },\n",
      "  \"source\": \"<a href=\\\"http://www.hootsuite.com\\\" rel=\\\"nofollow\\\">Hootsuite</a>\",\n",
      "  \"id_str\": \"778021969203720192\",\n",
      "  \"in_reply_to_user_id\": null,\n",
      "  \"retweeted\": false,\n",
      "  \"in_reply_to_screen_name\": null,\n",
      "  \"contributors\": null\n",
      " },\n",
      " \"text\": \"RT @buffboxx: Take a Day Off Between CrossFit Workouts, Study Says https://t.co/Wl1aDP0pxN\",\n",
      " \"lang\": \"en\",\n",
      " \"geo\": null,\n",
      " \"is_quote_status\": false,\n",
      " \"retweet_count\": 1,\n",
      " \"metadata\": {\n",
      "  \"iso_language_code\": \"en\",\n",
      "  \"result_type\": \"recent\"\n",
      " },\n",
      " \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\",\n",
      " \"id_str\": \"778044917532721152\",\n",
      " \"in_reply_to_user_id\": null,\n",
      " \"retweeted\": false,\n",
      " \"in_reply_to_screen_name\": null,\n",
      " \"contributors\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets and \n",
    "    # https://dev.twitter.com/docs/using-search for details on advanced \n",
    "    # search criteria that may be useful for keyword arguments\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://dev.twitter.com/docs/rate-limiting/1.1/limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError: # No more results when next_results doesn't exist\n",
    "            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "q = \"CrossFit\"\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "        \n",
    "# Show one sample search result by slicing the list...\n",
    "print (json.dumps(results[0], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "pp = partial(json.dumps, indent=1)\n",
    "\n",
    "twitter_world_trends = partial(twitter_trends, twitter_api, WORLD_WOE_ID)\n",
    "\n",
    "#print (pp(twitter_world_trends()))\n",
    "\n",
    "authenticated_twitter_search = partial(twitter_search, twitter_api)\n",
    "results = authenticated_twitter_search(\"iPhone\")\n",
    "#print (pp(results))\n",
    "\n",
    "authenticated_iphone_twitter_search = partial(authenticated_twitter_search, \"iPhone\")\n",
    "results = authenticated_iphone_twitter_search()\n",
    "#print (pp(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "    ''' if e.e.code == 401:\n",
    "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
    "            if sleep_when_rate_limited:\n",
    "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e '''\n",
    "        \n",
    "\n",
    "    # End of nested helper function \n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"URLError encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "        except BadStatusLine:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/users/lookup for \n",
    "# twitter_api.users.lookup\n",
    "\n",
    "response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                screen_name=\"SocialWebMining\")\n",
    "\n",
    "#print (json.dumps(response, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[376986779, 237527660, 460658453, 210567673, 3998034981, 327555798, 290809659, 183487809, 3115775917, 316901934, 3020277803, 252266942, 329385055, 829673054, 294318508, 2286022274, 1140790656, 220408962, 353990363, 128102424]\n",
      "[356431090, 501311935, 156047028, 482513187, 2856054773, 157587353, 2752198528, 56626487, 403146359, 13186912, 2881312943, 777543595167457280, 2960369602, 97781452, 2939724693, 3161650337, 2205768813, 3407958670, 778004773203169281, 99599151]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "#from sys import maxint\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=100000, followers_limit=100000):\n",
    "    \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/friends/ids and\n",
    "    # https://dev.twitter.com/docs/api/1.1/get/followers/ids for details\n",
    "    # on API parameters\n",
    "    \n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
    "                                count=5000)\n",
    "    \n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "    \n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        if limit == 0: continue\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "            #print('Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
    "                                                    #label, (user_id or screen_name)), end=\"\", file=sys.stderr)\n",
    "            #print >> sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
    "                                                    #label, (user_id or screen_name))\n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances\n",
    "        \n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    # Do something useful with the IDs, like store them to disk...\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=\"JimmyG_10\", \n",
    "                                                       friends_limit=20, \n",
    "                                                       followers_limit=20)\n",
    "\n",
    "print (friends_ids)\n",
    "print (followers_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JimmyG_10 is following 222\n",
      "JimmyG_10 is being followed by 70000\n",
      "201 of 222 are not following JimmyG_10 back\n",
      "69979 of 70000 are not being followed back by JimmyG_10\n",
      "JimmyG_10 has 21 mutual friends\n"
     ]
    }
   ],
   "source": [
    "def setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids):\n",
    "    \n",
    "    friends_ids, followers_ids = set(friends_ids), set(followers_ids)\n",
    "    \n",
    "    print ('{0} is following {1}'.format(screen_name, len(friends_ids)))\n",
    "\n",
    "    print ('{0} is being followed by {1}'.format(screen_name, len(followers_ids)))\n",
    "    \n",
    "    print ('{0} of {1} are not following {2} back'.format(\n",
    "            len(friends_ids.difference(followers_ids)), \n",
    "            len(friends_ids), screen_name))\n",
    "    \n",
    "    print ('{0} of {1} are not being followed back by {2}'.format(\n",
    "            len(followers_ids.difference(friends_ids)), \n",
    "            len(followers_ids), screen_name))\n",
    "    \n",
    "    print ('{0} has {1} mutual friends'.format(\n",
    "            screen_name, len(friends_ids.intersection(followers_ids))))\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "screen_name = \"JimmyG_10\"\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=screen_name)\n",
    "setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_profile(twitter_api, screen_names=None, user_ids=None):\n",
    "   \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_names != None) != (user_ids != None), \\\n",
    "    \"Must have screen_names or user_ids, but not both\"\n",
    "    \n",
    "    items_to_info = {}\n",
    "\n",
    "    items = screen_names or user_ids\n",
    "    \n",
    "    while len(items) > 0:\n",
    "\n",
    "        # Process 100 items at a time per the API specifications for /users/lookup.\n",
    "        # See https://dev.twitter.com/docs/api/1.1/get/users/lookup for details.\n",
    "        \n",
    "        items_str = ','.join([str(item) for item in items[:100]])\n",
    "        items = items[100:]\n",
    "\n",
    "        if screen_names:\n",
    "            response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                            screen_name=items_str)\n",
    "        else: # user_ids\n",
    "            response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                            user_id=items_str)\n",
    "    \n",
    "        for user_info in response:\n",
    "            if screen_names:\n",
    "                items_to_info[user_info['screen_name']] = user_info\n",
    "            else: # user_ids\n",
    "                items_to_info[user_info['id']] = user_info\n",
    "\n",
    "    return items_to_info\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "#print (get_user_profile(twitter_api, user_ids=[776252947449667584])) \n",
    "#print get_user_profile(twitter_api, user_ids=[132373965])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['como', 'vayanse', 'que', 'es', 'algo', 'a', 'Hasta', 'tÃ­a', 'QB', 'le', 'Jimmy', 'comieron', 'â€“Se', 'completo', 'escuchÃ³', 'tu', 'Brady', 'vez', 'JimÃ©nez', 'falta', 'para', 'retire', 'Helen?', 'indiscutible.', 'verga', 'Azcarate.', 'ðŸ˜‚ðŸ˜‚ðŸ˜ðŸ˜', 'excelente', 'nombre', '#NoANarcoSeries', 'los', 'una', 'el', 'Tom', 'â€“Y', 'titular', 'telenovela', 'Elba', 'la', 'sea', 'debe', 'Garoppolo', 'mÃ¡s...', 'ser', 'de', 'Televisa', 'mucho', 'pero', 'se', '@elbajimenez9', 'Hummels', '#SiANarcoSeries', 'eso', 'gatos', 'go', '@MagicJohnson', 'lunch', 'the', 'a', 'Semis', 'YOUR', 'have', '#GoAngels', 'CFP', 'https://t.co/eH3BW6fQrj', 'Ultimate', 'to', 'Man', 'attend', 'Halos', 'prevails', 'FIGHTING', 'Pizza', 'DAME', 'Northern', 'Rangers.', '#mmfridaysweeps', 'bowl!', 'see', 'pick', 'https://t.câ€¦', 'on', 'NOTRE', 'ALA/LSU.', 'take', 'Gooo', 'About', 'for', 'and', 'at', 'https://â€¦', 'Rules:', 'GO', 'time', '#NotreDameFootball', 'Trout', 'Catch', 'delivers!', '@jemelehill', 'in', 'Experience', 'game!', 'seeing', 'chance', 'YOU', '#PratEffect', 'RT', 'Dancer', 'https://t.co/w6aoRZ6dC8', 'IRISH!', '#mmwednesdaysweeps', 'Michael', 'Nelson', 'First', '@RogerLodge7.', '@BritneyEurton:', 'Tailgate', '@espngolic', 'The', '@MikeAndMike:', 'a', 'loves', 'one', 'without', 'you', 'roof', 'someone', 'first', 'Seriously', 'to', 'https://t.co/OdGVzNJXYX', 'when', 'just', 'want', 'You', 'love', 'who', '@adriananaxoxo:', 'https://t.co/SBC73XBoyq', 'his', 'telling', 'even', 'them', 'of', 'or', 'gotta', 'my', '@chanelpuke:', '!', 'show', '@InformationEra_:', 'me', 'tat', '@MarkersAlpo:', 'dont,', 'back', 'vs', 'I', 'job', 'neck', 'started', 'RT', 'become', 'rub', 'they', 'sombrero', 'When', 'will', 'now', 'que', 'hay', 'have', 'a', 'ya', 'Dios', '@_LuisRH:', 'lo', 'han', 'grande!', 'esta', '@jairpereira16', 'Jimmy', 'falta,', 'game', 'y', 'then', 'Brady', '#Patriots', '@BDiehards:', 'ahora', 'G', 'haciendo', '#LetsGoPats', 'hecho', 'pozolito.', 'Watching', 'and', 'me', 'https://t.co/v2gVWmjC1x', '@sinviaavelar:', 'get', 'Bendito', 'plan', 'https://t.co/jWLB0i5aKA', 'sea', 'RT', '@JimmyG_10', 'en', 'https://t.co/JStWlafkP9', 'muy', 'Cuando', 'hasta', 'dicen', '##LetsGoPats', 'Gronk', 'bien!', 'great', 'hurt', 'no', 'go', 'a', 'more', 'week,', \"it's\", 'you', 'guy', 'Can', 'do', 'here', 'like', 'â¤ï¸â¤ï¸â¤ï¸', 'https://t.co/Apx91Eu9nd', 'ðŸ¤‘ðŸ¤‘ily', 'what', 'this', '@FemaleTexts:', 'talk', 'https://t.co/ybDKp9BI8n', '14', 'days...', 'about', 'IN', 'needed', 'can', 'TEARS', 'me', 'https://t.co/FsZPUEdqV7', 'get', '@CauseWereComedy:', 'through', 'tho', 'please', 'I', 'that', 'RT', 'IM', '@girlposts:', 'LMFAOOOO', '@OnlyInBOS:', 'https://t.co/vmAafXphEx', '@_Jazzcat', 'sign', 'if', 'wants', 'exactly', 'have', 'most', 'upset.', 'how', 'bad.', 'bring', 'played', 'better', 'think', 'about', 'mention', 'Somebody', 'team.', 'caught', 'that', 'Gore', 'balls', 'upset', 'who', 'NC', 'beat', 'a', 'yesterday', 'an', 'game', '2014-15', '11â€¦', 'than', 'ransom', '@RealMikeWilbon', 'for', 'so', '@AlecBNathan', '#NoRespect', 'year.', '@thesportshero', '21st', 'sell', 'classic', 'the', 'Bennett', \"it's\", 'to', 'cent', 'not', 'wake', '@thefootballgirl', 'this', 'management', 'of', '5', 'my', 'Not', \"didn't\", 'some1', 'org', 'tell', 'ISU', 'in', 'I', 'RT', 'Martellus', \"'em\", 'Wentz/NDSU', 'he', 'Could', \"I'm\", 'bit', 'Bears', '@danpompei', 'wish', 'McCaskey', 'is', 'what', '@RealMikeWilbon:', 'and', '@WZJoshLopez', 'Jags', 'get', 'snaps', '80', 'SD', 'Redbirds', \"king's\", 'would', 'be', 'will', 'Edwards', 'the', 'This', 'a', 'FG', \"it's\", '@Will_Lockwood', 'to', 'SAT', 'scores', 'congrats', 'point', 'Herm', 'ridiculous', 'like', 'Berkley', '@jtrav728', 'between', 'champion', 'is', 'what', 'him', 'think', 'got', 'were', 'went', '-', 'and', 'https://t.co/VDRzd5Wl9f', 'for', 'SCKC', 'me', 'Randle', 'get', 'much.', 'too', 'into.\"', 'attempt', 'cards', 'in', 'tough', 'TD', 'that', 'Rueben', \"doesn't\", 'feel', 'Marshawn', 'school', \"Don't\", 'making', 'it', 'say', 'just', '\"a']\n",
      "[('a', 7), ('RT', 5), ('and', 4), ('to', 4), ('me', 4), ('get', 4), ('that', 3), ('for', 3), (\"it's\", 3), ('in', 3), ('what', 3), ('have', 3), ('the', 3), ('I', 3), ('just', 2), ('who', 2), ('go', 2), ('of', 2), ('sea', 2), ('about', 2), ('que', 2), ('Jimmy', 2), ('you', 2), ('think', 2), ('game', 2), ('this', 2), ('my', 2), ('like', 2), ('is', 2), ('Brady', 2), ('will', 2), ('wants', 1), ('how', 1), ('grande!', 1), ('exactly', 1), ('esta', 1), ('Halos', 1), ('when', 1), ('played', 1), ('then', 1), ('upset.', 1), ('@jtrav728', 1), ('chance', 1), ('para', 1), ('@chanelpuke:', 1), ('one', 1), ('ðŸ˜‚ðŸ˜‚ðŸ˜ðŸ˜', 1), ('team.', 1), ('much.', 1), ('Trout', 1), ('ransom', 1), ('Tom', 1), ('telenovela', 1), ('TD', 1), ('https://t.co/jWLB0i5aKA', 1), ('Rueben', 1), ('retire', 1), ('Garoppolo', 1), ('mÃ¡s...', 1), ('muy', 1), ('@BritneyEurton:', 1), ('upset', 1), ('they', 1), ('bien!', 1), ('now', 1), ('vayanse', 1), ('CFP', 1), ('Ultimate', 1), ('lo', 1), ('roof', 1), ('han', 1), ('someone', 1), ('Man', 1), ('https://t.co/OdGVzNJXYX', 1), ('yesterday', 1), ('comieron', 1), ('Can', 1), ('pero', 1), ('haciendo', 1), ('#LetsGoPats', 1), ('ALA/LSU.', 1), ('hecho', 1), ('or', 1), ('Gooo', 1), ('plan', 1), ('needed', 1), ('can', 1), ('at', 1), ('11â€¦', 1), ('too', 1), ('Catch', 1), ('los', 1), ('please', 1), ('@AlecBNathan', 1), ('â€“Y', 1), ('tough', 1), ('game!', 1), ('seeing', 1), ('neck', 1), ('la', 1), ('@JimmyG_10', 1), ('ser', 1), ('#mmwednesdaysweeps', 1), ('eso', 1), ('https://t.co/JStWlafkP9', 1), ('Nelson', 1), ('Cuando', 1), ('sombrero', 1), ('@espngolic', 1), ('@_Jazzcat', 1), ('The', 1), ('21st', 1), ('Edwards', 1), ('This', 1), ('Bennett', 1), ('Dios', 1), ('cent', 1), ('not', 1), ('making', 1), ('want', 1), ('Berkley', 1), ('Rangers.', 1), ('bowl!', 1), ('even', 1), ('him', 1), ('management', 1), ('##LetsGoPats', 1), ('gotta', 1), ('5', 1), ('were', 1), ('indiscutible.', 1), ('Not', 1), ('some1', 1), ('org', 1), ('time', 1), ('ISU', 1), ('@jemelehill', 1), ('back', 1), ('Bendito', 1), ('days...', 1), ('job', 1), ('loves', 1), ('Martellus', 1), ('IRISH!', 1), ('Wentz/NDSU', 1), ('First', 1), ('ya', 1), ('dicen', 1), ('he', 1), (\"Don't\", 1), ('Tailgate', 1), ('Hummels', 1), ('sign', 1), ('no', 1), ('como', 1), ('escuchÃ³', 1), ('Hasta', 1), ('-', 1), ('#GoAngels', 1), ('https://t.co/eH3BW6fQrj', 1), ('QB', 1), ('first', 1), ('SAT', 1), ('@jairpereira16', 1), ('prevails', 1), ('here', 1), ('McCaskey', 1), ('completo', 1), ('ahora', 1), ('see', 1), ('his', 1), ('take', 1), ('https://t.co/ybDKp9BI8n', 1), ('Marshawn', 1), ('show', 1), ('@WZJoshLopez', 1), ('nombre', 1), ('dont,', 1), ('tho', 1), ('el', 1), ('80', 1), ('Dancer', 1), ('#Patriots', 1), ('SD', 1), ('Televisa', 1), ('if', 1), ('become', 1), ('more', 1), ('would', 1), ('school', 1), ('be', 1), ('hurt', 1), ('@MikeAndMike:', 1), ('lunch', 1), ('hay', 1), ('most', 1), ('classic', 1), ('https://t.co/Apx91Eu9nd', 1), ('bad.', 1), ('falta,', 1), ('bring', 1), ('point', 1), ('Herm', 1), ('Semis', 1), ('between', 1), ('telling', 1), ('better', 1), ('NOTRE', 1), ('@FemaleTexts:', 1), ('falta', 1), ('Helen?', 1), ('mention', 1), ('Somebody', 1), ('GO', 1), ('@sinviaavelar:', 1), ('@CauseWereComedy:', 1), ('caught', 1), ('Gore', 1), ('balls', 1), ('feel', 1), ('rub', 1), ('LMFAOOOO', 1), ('se', 1), ('it', 1), ('https://t.co/vmAafXphEx', 1), ('\"a', 1), ('tell', 1), ('NC', 1), ('@MagicJohnson', 1), ('beat', 1), ('es', 1), ('algo', 1), ('FG', 1), ('tÃ­a', 1), ('@InformationEra_:', 1), ('guy', 1), ('scores', 1), ('attend', 1), ('an', 1), ('@RealMikeWilbon:', 1), ('tu', 1), ('DAME', 1), ('https://t.co/v2gVWmjC1x', 1), ('vez', 1), ('https://t.câ€¦', 1), ('ðŸ¤‘ðŸ¤‘ily', 1), ('than', 1), ('@RealMikeWilbon', 1), ('!', 1), ('went', 1), ('@OnlyInBOS:', 1), ('so', 1), ('https://â€¦', 1), ('say', 1), ('#NotreDameFootball', 1), ('into.\"', 1), ('cards', 1), ('#NoRespect', 1), ('started', 1), ('#PratEffect', 1), ('@girlposts:', 1), ('year.', 1), ('#mmfridaysweeps', 1), ('@thesportshero', 1), ('@adriananaxoxo:', 1), ('Gronk', 1), ('@elbajimenez9', 1), ('#SiANarcoSeries', 1), ('great', 1), ('sell', 1), ('gatos', 1), ('@thefootballgirl', 1), ('on', 1), ('week,', 1), ('le', 1), ('@Will_Lockwood', 1), ('You', 1), ('congrats', 1), ('vs', 1), ('YOUR', 1), ('Pizza', 1), ('Northern', 1), ('â¤ï¸â¤ï¸â¤ï¸', 1), ('wake', 1), ('@BDiehards:', 1), ('https://t.co/SBC73XBoyq', 1), ('G', 1), ('Watching', 1), ('@_LuisRH:', 1), (\"didn't\", 1), ('talk', 1), ('Rules:', 1), ('#NoANarcoSeries', 1), ('@MarkersAlpo:', 1), ('attempt', 1), ('through', 1), ('https://t.co/w6aoRZ6dC8', 1), ('About', 1), ('IM', 1), (\"doesn't\", 1), ('en', 1), (\"'em\", 1), ('Michael', 1), ('@RogerLodge7.', 1), ('de', 1), ('hasta', 1), ('Could', 1), (\"I'm\", 1), ('without', 1), ('bit', 1), ('Bears', 1), ('Seriously', 1), ('do', 1), ('@danpompei', 1), ('https://t.co/VDRzd5Wl9f', 1), ('wish', 1), ('FIGHTING', 1), ('â€“Se', 1), ('SCKC', 1), ('y', 1), ('ridiculous', 1), ('Azcarate.', 1), ('love', 1), ('champion', 1), ('pick', 1), ('them', 1), ('JimÃ©nez', 1), ('got', 1), ('14', 1), ('pozolito.', 1), ('IN', 1), ('verga', 1), ('TEARS', 1), ('tat', 1), ('excelente', 1), ('Jags', 1), ('https://t.co/FsZPUEdqV7', 1), ('Randle', 1), ('una', 1), ('YOU', 1), ('titular', 1), ('Experience', 1), ('snaps', 1), ('Elba', 1), ('debe', 1), ('Redbirds', 1), ('mucho', 1), (\"king's\", 1), ('delivers!', 1), ('When', 1), ('2014-15', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def harvest_user_timeline(twitter_api, screen_name=None, user_id=None, max_results=1000):\n",
    "     \n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"    \n",
    "    \n",
    "    kw = {  # Keyword args for the Twitter API call\n",
    "        'count': 200,\n",
    "        'trim_user': 'true',\n",
    "        'include_rts' : 'true',\n",
    "        'since_id' : 1\n",
    "        }\n",
    "    \n",
    "    if screen_name:\n",
    "        kw['screen_name'] = screen_name\n",
    "    else:\n",
    "        kw['user_id'] = user_id\n",
    "        \n",
    "    max_pages = 16\n",
    "    results = []\n",
    "    \n",
    "    tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "    \n",
    "    if tweets is None: # 401 (Not Authorized) - Need to bail out on loop entry\n",
    "        tweets = []\n",
    "        \n",
    "    results += tweets\n",
    "    \n",
    "    #print >> sys.stderr, 'Fetched %i tweets' % len(tweets)\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # Many Twitter accounts have fewer than 200 tweets so you don't want to enter\n",
    "    # the loop and waste a precious request if max_results = 200.\n",
    "    \n",
    "    # Note: Analogous optimizations could be applied inside the loop to try and \n",
    "    # save requests. e.g. Don't make a third request if you have 287 tweets out of \n",
    "    # a possible 400 tweets after your second request. Twitter does do some \n",
    "    # post-filtering on censored and deleted tweets out of batches of 'count', though,\n",
    "    # so you can't strictly check for the number of results being 200. You might get\n",
    "    # back 198, for example, and still have many more tweets to go. If you have the\n",
    "    # total number of tweets for an account (by GET /users/lookup/), then you could \n",
    "    # simply use this value as a guide.\n",
    "    \n",
    "    if max_results == kw['count']:\n",
    "        page_num = max_pages # Prevent loop entry\n",
    "    \n",
    "    while page_num < max_pages and len(tweets) > 0 and len(results) < max_results:\n",
    "    \n",
    "        # Necessary for traversing the timeline in Twitter's v1.1 API:\n",
    "        # get the next query's max-id parameter to pass in.\n",
    "        # See https://dev.twitter.com/docs/working-with-timelines.\n",
    "        kw['max_id'] = min([ tweet['id'] for tweet in tweets]) - 1 \n",
    "    \n",
    "        tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "        results += tweets\n",
    "\n",
    "        #print >> sys.stderr, 'Fetched %i tweets' % (len(tweets),)\n",
    "    \n",
    "        page_num += 1\n",
    "        \n",
    "    #print >> sys.stderr, 'Done fetching tweets'\n",
    "\n",
    "    return results[:max_results]\n",
    "    \n",
    "# Sample usage\n",
    "\n",
    "#twitter_api = oauth_login()\n",
    "\n",
    "#tweets = []\n",
    "important = []\n",
    "for j in range(9):\n",
    "    tweets=harvest_user_timeline(twitter_api, user_id=followers_ids[j], \\\n",
    "                                   max_results=40)\n",
    "    if len(tweets)>5:\n",
    "        unimportant =[]\n",
    "        for i in range(5):\n",
    "            unimportant.append(tweets[i][\"text\"])\n",
    "        important.append(unimportant)\n",
    "        \n",
    "#print(important)\n",
    "\n",
    "status_texts = important\n",
    "\n",
    "#print(status_texts)\n",
    "\n",
    "words=[]\n",
    "\n",
    "for user in status_texts:\n",
    "    userword=[]\n",
    "    for tweet in user:\n",
    "        for word in tweet.split():\n",
    "            userword.append(word)\n",
    "    for word in list(set(userword)):\n",
    "        words.append(word)\n",
    "        \n",
    "        \n",
    "\n",
    "#words = [ w \n",
    "    #      for t in status_texts \n",
    "        #      for w in list(Counter(t.split()).keys)\n",
    "              #      ]\n",
    "\n",
    "#for t in status_texts:\n",
    "   # s = t.split():\n",
    "    #for w in list(Counter(s).keys()):\n",
    "        \n",
    "        \n",
    "#words = [ w \n",
    "          #for w in list(Counter(r).keys())]\n",
    "\n",
    "print (words)\n",
    "\n",
    "\n",
    "#tweet_entities = [d\n",
    "          #        for d in words \n",
    "          #       ]\n",
    "#print(tweet_entities)\n",
    "\n",
    "print(Counter(words).most_common())\n",
    "\n",
    "\n",
    "#print(tweets)\n",
    "\n",
    "# Save to MongoDB with save_to_mongo or a local file with save_json..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lindsey_prince', 'ALEJANDROAZC', 'Tremendous61', 'dannnielle_', 'PatMoon123', 'ArturoCamachoS', '_sophiapeterson', 'Tim_Carroll00', 'KingBGK', 'Calif3Girl']\n"
     ]
    }
   ],
   "source": [
    "screen_names=[]\n",
    "for j in range(10):\n",
    "    screen_names.append(get_user_profile(twitter_api, user_ids=[followers_ids[j]])) \n",
    "#print(screen_names)\n",
    "screen_names_2=[]\n",
    "for j in range(10):\n",
    "    screen_names_2.append(screen_names[j][followers_ids[j]][\"screen_name\"])\n",
    "print(screen_names_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
